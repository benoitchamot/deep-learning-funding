# deep-learning-funding
Create a binary classifier that can predict whether applicants will be successful if funded, with an accuracy of 75% or better

### Summary
TODO: Summarise the overall results of the deep learning model. Include a recommendation for how a different model could solve this classification problem, and then explain your recommendation.

## File structure
* The `img` directory contains the charts and graphics generated by the Jupyter notebooks and used in this README file
* The `tmp` directory contains the weights saved during training in Step 1
* `AlphabetSoupCharity_Optimisation.h5` is a binary file containing the optimised model from Step 2
* `AlphabetSoupCharity.h5` is a binary file containing the model from Step 1
* The `StepN_*.ipynb` files are the Jupyter notebooks used in steps `N = 1-4` detailed below

## About the data
### Source
The data is provided by Monash University: https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv

### Columns in the dataset CSV
* `EIN` and `NAME` — Identification columns
* `APPLICATION_TYPE` — Alphabet Soup application type
* `AFFILIATION` — Affiliated sector of industry
* `CLASSIFICATION` — Government organisation classification
* `USE_CASE` — Use case for funding
* `ORGANIZATION` — Organisation type
* `STATUS` — Active status
* `INCOME_AMT` — Income classification
* `SPECIAL_CONSIDERATIONS` — Special considerations for application
* `ASK_AMT` — Funding amount requested
* `IS_SUCCESSFUL` — Was the money used effectively

## Report
### Overview of the analysis
The purpose of the analysis is to optimise a neural network to classify applications for crowdfunding and predict whether they will be succesful.

### Research questions

**Data Preprocessing**
> **Question 1**: What variable(s) are the target(s) for your model?

We classify against the `IS_SUCCESSFUL` column: `1` for succesful and `0` for unsuccesful

> **Question 2**: What variable(s) should be removed from the input data because they are neither targets nor features?

The identification columns `EIN` and `NAME` are removed as they are first thought to provide no valuable information. This is revisted in Step 3 (see below) where `NAME` is added back as a feature.

> **Question 3**: What variable(s) are the features for your model?

We use all the columns in the CSV apart from `IS_SUCCESSFUL`, `EIN` and `NAME` (see Step 3)

**Compiling, Training, and Evaluating the Model**
> **Question 4**: What steps did you take in your attempts to increase model performance?

See next Section: `Approach`

> **Question 5**: How many neurons, layers, and activation functions did you select for your neural network model, and why?

See Section: `Results`

> **Question 6**: Were you able to achieve the target model performance (75%)?

Yes, by using the `NAME` as one of the features, we achieve an accuracy of 80%. We do however have some reservations about this approach which is discussed in the Section: `Conclusions`. In general, an accuracy closer to 72% should be expect from the model.

### Approach
We take four main steps to approach the problem, as presented in this section.

#### Step 1: First attempt
The first step was simply to establish a baseline by constructing a simple network to get some preliminary results. The accuracy is used as the metric to optimise (this is the case in the next steps too.)

The data are prepared in the following way:
1. Import complete dataset and load it into a pandas DataFrame
2. Drop the `EIN` and `NAME` columns
3. Group the application types with a number of entries below 500 together into an 'other' type
4. Group the classification types with a number of entries below 1000 together into an 'other' type
5. Create dummies with all categorical columns
6. Split the data into training and test sets
7. Scale the data using a standard scaler

The model is then trained, evaluated and saved in the `AlphabetSoupCharity.h5` binary file.

#### Step 2: Manual and automated tuning exploration

#### Step 3: Using `NAME` as a feature
After discussion with some peers, it seems that adding the `NAME` column back as a feature could significantly improves the results. We look at this option in Step 3.

#### Step 4: Pruning and simplification
During this step, we look again at the original data, without using `NAME`. More reading and research went into this step to understand industry's best practices and common approach. We look at a model with as few neurons and epochs as possible to accelerate the training.

### Results
In Step 1, we built a simple preliminary model with the following structure:

<img src=img/model_1.png>

The output layer use a `sigmoid` activation function while all the other layers use `relu`. The model achieve an accuracy of 72.34% which is already close to the target of 75%.

### Conclusions

